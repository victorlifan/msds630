{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pytorch libraries\n",
    "%matplotlib inline\n",
    "import torch \n",
    "import torch.autograd as autograd \n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6, 7])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embed = nn.Embedding(5,7)\n",
    "x = torch.LongTensor([1,0,1,4,2,1])\n",
    "embed(x).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3., 3., 3.])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x= torch.tensor([1.,2.,3.],requires_grad=True)\n",
    "L = (3*x+7).sum()\n",
    "L.backward()\n",
    "x.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intro to Pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyTorch consists of 4 main packages:\n",
    "* torch: a general purpose array library similar to Numpy that can do computations on GPU\n",
    "* torch.autograd: a package for automatically obtaining gradients\n",
    "* torch.nn: a neural net library with common layers and cost functions\n",
    "* torch.optim: an optimization package with common optimization algorithms like SGD, Adam, etc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pytorch tensors\n",
    "Like Numpy tensors but can utilize GPUs to accelerate its numerical computations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating tensors from lists or numpy arrays\n",
    "x = torch.tensor([[1, 2],[3, 4]])\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create random tensor\n",
    "N = 5\n",
    "x = torch.randn(N, 10).type(torch.FloatTensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
<<<<<<< HEAD
       "tensor([[ 0.4165,  0.7731,  0.8064,  0.1773,  2.1272, -1.3241,  0.7010,  0.2305,\n",
       "          1.4417, -1.2797],\n",
       "        [ 1.3633,  1.3258, -0.1340, -0.2785, -0.0491,  0.8963, -1.1539, -0.1368,\n",
       "         -0.0121,  1.3126],\n",
       "        [ 0.3172,  0.6311,  0.3991,  2.2125,  1.3015,  0.6921,  0.2520, -0.4936,\n",
       "          1.7392,  1.6684],\n",
       "        [-0.1385, -1.4701, -0.5521,  1.9179,  0.0032, -0.7064,  1.2200,  1.8945,\n",
       "          0.6468,  0.7040],\n",
       "        [ 0.4570,  0.5386,  1.1183,  0.6016, -0.4310, -1.7574, -0.7426,  0.1117,\n",
       "         -0.5684,  2.6981]])"
=======
       "torch.Size([5, 10])"
>>>>>>> upstream/main
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
<<<<<<< HEAD
       "tensor([[ 0.4165,  0.7731,  0.8064,  0.1773,  2.1272, -1.3241,  0.7010,  0.2305,\n",
       "          1.4417, -1.2797,  1.3633,  1.3258, -0.1340, -0.2785, -0.0491,  0.8963,\n",
       "         -1.1539, -0.1368, -0.0121,  1.3126,  0.3172,  0.6311,  0.3991,  2.2125,\n",
       "          1.3015,  0.6921,  0.2520, -0.4936,  1.7392,  1.6684, -0.1385, -1.4701,\n",
       "         -0.5521,  1.9179,  0.0032, -0.7064,  1.2200,  1.8945,  0.6468,  0.7040,\n",
       "          0.4570,  0.5386,  1.1183,  0.6016, -0.4310, -1.7574, -0.7426,  0.1117,\n",
       "         -0.5684,  2.6981]])"
=======
       "tensor([[-1.7481, -0.9594,  1.3700, -0.6536, -0.4444, -0.4546,  0.2393,  0.5466,\n",
       "          0.6029, -0.0886, -0.9079,  0.4814,  0.2296,  0.8491,  0.2712,  1.8901,\n",
       "          0.9042,  0.6683, -1.4789, -1.0898,  0.0459, -0.5641,  0.7949,  1.0128,\n",
       "         -0.5180,  0.8064, -0.1605,  0.0410,  0.7690,  0.1904,  1.0563,  1.2471,\n",
       "          2.0734,  0.2857,  0.7451,  0.3704, -0.2975, -0.3238, -2.0436, -0.1730,\n",
       "         -1.5690, -0.2365,  0.1452, -0.5777,  1.3472,  0.3471, -0.2458,  1.0638,\n",
       "          2.1069,  0.7155]])"
>>>>>>> upstream/main
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reshaping of tensors using .view()\n",
    "x.view(1,-1) #-1 makes torch infer the second dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 50])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.view(1,-1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
<<<<<<< HEAD
       "array([[ 0.4165289 ,  0.77310413,  0.80642456,  0.17733215,  2.1271744 ,\n",
       "        -1.3240715 ,  0.70098394,  0.23047732,  1.4416903 , -1.2796512 ],\n",
       "       [ 1.3633089 ,  1.3257879 , -0.13398595, -0.2784902 , -0.04914783,\n",
       "         0.8963281 , -1.1539116 , -0.13680276, -0.01210461,  1.3125829 ],\n",
       "       [ 0.31720132,  0.6311008 ,  0.3990803 ,  2.212454  ,  1.3015145 ,\n",
       "         0.69208366,  0.2520219 , -0.49357614,  1.7391502 ,  1.6683606 ],\n",
       "       [-0.13849248, -1.4701432 , -0.55207795,  1.917912  ,  0.00316071,\n",
       "        -0.70637834,  1.2199775 ,  1.8944525 ,  0.64683473,  0.70395505],\n",
       "       [ 0.4569876 ,  0.53863686,  1.1182747 ,  0.6016298 , -0.430964  ,\n",
       "        -1.7573506 , -0.7426433 ,  0.11167649, -0.5683516 ,  2.6981385 ]],\n",
=======
       "array([[-1.7480742 , -0.9593931 ,  1.3699764 , -0.65356874, -0.44440666,\n",
       "        -0.45458245,  0.23928294,  0.5466492 ,  0.602928  , -0.08858541],\n",
       "       [-0.9079101 ,  0.48138094,  0.22963923,  0.84911245,  0.2712227 ,\n",
       "         1.890109  ,  0.90424967,  0.66833395, -1.478872  , -1.0897563 ],\n",
       "       [ 0.04591583, -0.5641075 ,  0.79489297,  1.0127643 , -0.51795614,\n",
       "         0.8064038 , -0.1604978 ,  0.04097979,  0.7689716 ,  0.19038403],\n",
       "       [ 1.0563445 ,  1.2471156 ,  2.073372  ,  0.28566024,  0.74511415,\n",
       "         0.37038982, -0.29746354, -0.323798  , -2.0435905 , -0.1730036 ],\n",
       "       [-1.5690292 , -0.23646528,  0.14521025, -0.57773626,  1.3471718 ,\n",
       "         0.34710705, -0.24580973,  1.0637664 ,  2.1068652 ,  0.7154719 ]],\n",
>>>>>>> upstream/main
       "      dtype=float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from tensors to numpy arrays\n",
    "x.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pytorch Autograd\n",
    "The autograd package in PyTorch provides classes and functions implementing automatic differentiation of arbitrary scalar valued function. For example, the gradient of the error with respect to all parameters.\n",
    "\n",
    "`requires_grad=True` tells PyTorch that it needs to calculate the gradient with respect to this tensor. Here is an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 2., 3., 4., 5., 6.], requires_grad=True)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor([1., 2., 3., 4., 5., 6.], requires_grad=True)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is equivalent\n",
    "x = torch.tensor([1., 2., 3., 4., 5., 6.]).requires_grad_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 3.,  9., 19., 33., 51., 73.], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2*x**2 + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(31.3333, grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L = (2*x**2 +1).mean()\n",
    "L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "L.backward() # computes the grad of L with respect to x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.6667, 1.3333, 2.0000, 2.6667, 3.3333, 4.0000])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
<<<<<<< HEAD
       "tensor([[-0.6501, -0.9515, -1.4159],\n",
       "        [ 0.7641, -1.9491,  1.8075]], requires_grad=True)"
=======
       "tensor([[-0.2445,  1.6367,  0.1279],\n",
       "        [-0.1026,  0.7715, -1.8319]], requires_grad=True)"
>>>>>>> upstream/main
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# here is another example\n",
    "x = torch.randn(2, 3)\n",
    "x.requires_grad = True\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
<<<<<<< HEAD
       "tensor(10.9825, grad_fn=<SumBackward0>)"
=======
       "tensor(1.0713, grad_fn=<SumBackward0>)"
>>>>>>> upstream/main
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L = (3*x).sum()\n",
    "L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
<<<<<<< HEAD
       "tensor([[-1.3002, -1.9030, -2.8318],\n",
       "        [ 1.5282, -3.8982,  3.6150]])"
=======
       "tensor([[3., 3., 3.],\n",
       "        [3., 3., 3.]])"
>>>>>>> upstream/main
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L.backward()\n",
    "x.grad # note, it is the same shape as x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## detach()\n",
    "The detach() method constructs a new view on a tensor which is declared not to need gradients. This may be needed for example when you want to take the output to a model to numpy to compute a metric with sklean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.24449883,  1.6366688 ,  0.12790135],\n",
       "       [-0.10264746,  0.771523  , -1.8318589 ]], dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.detach().numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run `x.numpy()` on x after the previous computation. See what happens. How would you fix this error?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.01373001, -0.03481031, -1.2227389 ],\n",
       "       [-0.5343777 , -0.6910662 , -0.16887644]], dtype=float32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.detach().numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## with torch.no_grad()\n",
    "Prevent the gradients from being calculated in a piece of code. This is useful at validation time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## torch.nn module\n",
    "A neural net library with common layers and cost functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`nn.Linear(5, 3)` creates a linear transformation with parameters $A$ and $b$ ($A\\cdot X+b$). Given an input matrix of observations $X$ ($N \\times 5$), `nn.Linear(5, 3)` transforms X into a $N \\times 3$ matrix, where $N$ can be anything (number of observations)."
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 27,
=======
   "execution_count": 19,
>>>>>>> upstream/main
   "metadata": {},
   "outputs": [],
   "source": [
    "D = 5 # number of input featutes\n",
    "M = 3 # neurons in the first hidden layer\n",
    "linear_map = nn.Linear(D, M)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 28,
=======
   "execution_count": 20,
>>>>>>> upstream/main
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
<<<<<<< HEAD
       " tensor([[-0.1339, -0.3044, -0.3950,  0.1027, -0.1301],\n",
       "         [ 0.3998,  0.4426,  0.4247, -0.3820,  0.1439],\n",
       "         [-0.2923,  0.4060,  0.3235,  0.3360, -0.3206]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([0.3953, 0.4135, 0.2163], requires_grad=True)]"
      ]
     },
     "execution_count": 28,
=======
       " tensor([[ 0.3144, -0.0660,  0.3990,  0.0812,  0.3175],\n",
       "         [-0.3104,  0.2984,  0.1506, -0.1336,  0.1550],\n",
       "         [ 0.2048,  0.4024, -0.3345, -0.1245,  0.2300]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([-0.1191, -0.2709, -0.2018], requires_grad=True)]"
      ]
     },
     "execution_count": 20,
>>>>>>> upstream/main
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# parameters are initialized randomly\n",
    "list(linear_map.parameters())"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 29,
=======
   "execution_count": 21,
>>>>>>> upstream/main
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[torch.Size([3, 5]), torch.Size([3])]"
      ]
     },
<<<<<<< HEAD
     "execution_count": 29,
=======
     "execution_count": 21,
>>>>>>> upstream/main
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# shape of parameters\n",
    "[p.shape for p in linear_map.parameters()]"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 30,
=======
   "execution_count": 22,
>>>>>>> upstream/main
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[15, 3]"
      ]
     },
<<<<<<< HEAD
     "execution_count": 30,
=======
     "execution_count": 22,
>>>>>>> upstream/main
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# total number of elements per parameter tensor. \n",
    "[p.numel() for p in linear_map.parameters()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise:** Create a layer with 20 input features  and 10 output features. Compute how many total parameters do you have. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[200, 10]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[p.numel() for p in nn.Linear(20,10).parameters()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Linear Regression with Pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of linear regression is to fit a line to a set of points."
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 2,
=======
   "execution_count": 23,
>>>>>>> upstream/main
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we generate some fake data\n",
    "def lin(a,b,x): return a*x+b\n",
    "\n",
    "def gen_fake_data(n, a, b):\n",
    "    x = np.random.uniform(0,1,n) \n",
    "    y = lin(a,b,x) + 0.1 * np.random.normal(0,3,n)\n",
    "    return x, y\n",
    "\n",
    "x, y = gen_fake_data(50, 3., 8.)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 4,
=======
   "execution_count": 24,
>>>>>>> upstream/main
   "metadata": {},
   "outputs": [
    {
     "data": {
<<<<<<< HEAD
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY0AAAEGCAYAAACZ0MnKAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAW3klEQVR4nO3df7DldX3f8efLhQiKSfhxRUSWhQk6WtokekC0qaXFWHQYmBqr2DqiQ9xqRa1p0zDTmeqQZqqTtM3EZEI3wmCaBjHE6taQIIMaklaYvWBUwFHXBWFXkKsgDhUNC+/+cQ71erz37vf+ON/v+Z7zfMzs7Dnf87nffX/PnD3v+/m8P5/PN1WFJElNPKXrACRJ/WHSkCQ1ZtKQJDVm0pAkNWbSkCQ1dljXAWyV4447rnbs2NF1GJLUK7feeuu3qmqhafuZSRo7duxgcXGx6zAkqVeSfH097R2ekiQ1ZtKQJDVm0pAkNWbSkCQ1ZtKQJDVm0pAkNWbSkNQ7+5Ye4Zo997Bv6ZGuQ5k7M7NOQ9J82Lf0COd94K+pggQ+8Y5f4NSFo7oOa25MrKeR5MokDyS5fdmxf5bkjiRPJBms8bPnJvlykr1JLp1UjJL6Z8/dD1IFjz72OFXD52rPJIenrgLOHTt2O/Bq4KbVfijJNuD3gFcCLwBen+QFE4pRUs+cseMYEjjy8G0kw+fzqKshuokNT1XVTUl2jB37EkCStX70TGBvVe0btf0wcAFw52QildQnpy4cxSfe8QvsuftBzthxzFwOTXU5RDeNNY0TgXuXPd8PvHilhkl2AjsBtm/fPvnIJE2FUxeOmstk8aTlQ3RHHr6NPXc/2Nr70evZU1W1q6oGVTVYWGi8SaMk9VqXQ3TT2NM4AJy07PlzRsckSXQ7RDeNSWMPcFqSUxgmiwuBf95tSJI0XboaopvklNurgc8Cz0uyP8nFSf5pkv3AS4A/S3L9qO2zk1wHUFUHgUuA64EvAR+pqjsmFackqblUVdcxbInBYFDehElS3+xbeqTTmWBJbq2qVdfNjZvG4SlJmgt9XN3e69lTktRnfVzdbtKQpI70cXW7w1OS1JE+rm43aUjSJmy2kN231e0mDUnaoD4WsjfLmoYkbVAfC9mbZdKQpA3qYyF7sxyekqQN6mMhe7NMGpK0CX0rZG+Ww1OSpMZMGpKkxkwakqTGTBqS1GP7lh7hmj33sG/pkVb+PQvhktRTXSwutKchST3VxeJCk4Yk9VQXiwsdnpKknupicaFJQ5J6rO3FhQ5PSZp7bc9A6rOJ9TSSXAmcBzxQVaePjh0DXAPsAO4GXltVD63ws48DXxw9vaeqzp9UnJLm2zxub74Zk+xpXAWcO3bsUuDGqjoNuHH0fCWPVtXPjf6YMCRtmfFexTxub74ZE+tpVNVNSXaMHb4AOHv0+EPAZ4Bfm1QMkrTcSr2KedzefDPaLoQfX1X3jR7fDxy/SrsjkiwCB4H3VdXHVmqUZCewE2D79u1bHKqkWbO8V3Hk4dvYc/eDvO6M7XO3vflmdDZ7qqoqSa3y8slVdSDJqcCnknyxqr62wjl2AbsABoPBaueSJGD1dQ1bNQNps/cL74O2k8Y3k5xQVfclOQF4YKVGVXVg9Pe+JJ8Bfh74saQhSesxyXUN81JQb3vK7W7gotHji4CPjzdIcnSSp44eHwf8feDO1iKUNNNOXTiK152xfcu/0OeloD6xpJHkauCzwPOS7E9yMfA+4BeTfBV4+eg5SQZJPjj60ecDi0k+D3yaYU3DpCFpqs1LQT1Vs1EKGAwGtbi42HUYkuZYH2saSW6tqkHT9m4jIqkzffySXcs83C/cpCGpE/NSOJ417j0lqRPzUjheSZ/3urKnIakT81I4Htf3HpZJQ1InurgXxDRYaVV6n67dpCGpM/NQOB7X9x6WSUOSWtT3HpZJQ+rArE01nbXrmbQ+97BMGlLL+l4IHTdr16O1OeVWatmsTTXt2/X0ebrrNLCnIbWs74XQcX26HntFm2fSkFrW90LouD5dT9+nu04Dk4bUgT4XQlfSl+vpU69oWpk0JM2NPvWKppVJQ9Jc6UuvaFo5e0qS1JhJQ5LUmElDktSYSUOS1NjEkkaSK5M8kOT2ZceOSXJDkq+O/j56lZ+9aNTmq0kumlSMkn7IldJqYpI9jauAc8eOXQrcWFWnATeOnv+IJMcA7wFeDJwJvGe15CJpazy5Uvq9u+/kvA/89VQmDpPadJjYlNuquinJjrHDFwBnjx5/CPgM8Gtjbf4JcENVPQiQ5AaGyefqScUqzbtpXynt9h/To+2axvFVdd/o8f3A8Su0ORG4d9nz/aNjPybJziSLSRaXlpa2NlJpjmx0pXRbv/33bVPEWdbZ4r6qqiS1yXPsAnYBDAaDTZ1LmmcbWSnd5m//z/rJI3j8iSd46mFPcfuPjrXd0/hmkhMARn8/sEKbA8BJy54/Z3RM0gSdunAUrztje+Mv/rZ++9+39Ahv+x+3kYQq+P1/8UKHpjrUdtLYDTw5G+oi4OMrtLkeeEWSo0cF8FeMjkmaIm1t/vdkcvrBwSfY9pRw/3e/P5F/R81MbHgqydUMi97HJdnPcEbU+4CPJLkY+Drw2lHbAfDWqvrlqnowya8De0anuuzJorik6dHW5n/uTDtdUjUbpYDBYFCLi4tdhyFpAla6B7n3Jd8aSW6tqkHT9u5yK2nqje9M6xTc7riNiKTecQpud0waknrHOkd3HJ6S1Dvega87Jg1JveQd+Lrh8JQkqTGThtQD7vCqaeHwlDTluppe6joIrcSkIU25LrYtdx2EVuPwlDTluphe6joIrcaehjTluphe6joIrcakIfVA29NLXQeh1Zg0JK3IdRBaiTUNSVJjJg21wnUG8jMwGxye0sQ5fVN+BmaHPQ1NnNM3Z8Nmegpb/Rmw19IdexqaOKdv9t9mewpb+Rmw19Itk4Ymzumb/bfZVelb+RnoYoW8fsikoVY4fbM/Vtpzait6Clv1GbDn2q1UVfv/aPIu4C1AgD+oqt8ee/1s4OPAXaNDH62qy9Y652AwqMXFxS2PVZonaw39TNMGhtMUS98lubWqBk3bt97TSHI6w4RxJvC3wF8k+URV7R1r+ldVdV7b8UnzbK2hn2nqLU5TLPOmi9lTzwduqarvVdVB4C+BV3cQhzQRa83smfZZPw796FC6qGncDvxGkmOBR4FXASuNK70kyeeBbwD/tqruGG+QZCewE2D79u2Ti1hq6FDDO+ud9dP2MIyTFnQorSeNqvpSkvcDnwT+L/A3wONjzW4DTq6qR5K8CvgYcNoK59oF7IJhTWOCYUuNrDW8s95ZP11NLXXoR2vpZHFfVV1RVS+qqpcBDwFfGXv9u1X1yOjxdcDhSY7rIFRpXdYa3lnv0I+LIjWNOplym+SZVfVAku0M6xlnjb3+LOCbVVVJzmSY3L7dQajSuqw1vLPeoR/rC5pGXa3T+NNRTeMx4O1V9Z0kbwWoqsuB1wBvS3KQYd3jwupibrC0AWsN76xn6Mf6gqZRJ+s0JsF1GmqbawU0C6Z+nYY0C9z/SPPKXW41c9pYC2GRWvPKnoZmSls9AIvUmleHTBpJ3gH8UVU91EI80qa0tQOqRWrNqyY9jeOBPUluA64Erncmk6ZVmz0AF8FpHjWaPZUkwCuANwMD4CPAFVX1tcmG15yzp/QkZzVJzU1k9tRokd39wP3AQeBo4NokN1TVv9tYqNJk2AOQJqdJTeNdwBuBbwEfBH61qh5L8hTgq4BJQ5LmRJOexjHAq6vq68sPVtUTSbzfhSTNkUMmjap6zxqvfWlrw5EkTTMX90mSGjNpSJIaM2lIkhozaUiSGjNpaN3a2BBQ0nRyw0Kti1uCS/PNnobWxS3Bpflm0tC6uCW4NN8cntK6uCW4NN866WkkeVeS25PckeRfr/B6kvxOkr1JvpDkhR2EqVWcunAUrztjuwlDmkOtJ40kpwNvAc4EfhY4L8nPjDV7JXDa6M9O4PdbDVKStKIuehrPB26pqu9V1UHgL4FXj7W5APjDGroZ+OkkJ7QdqGbLalOFnUIsNddFTeN24DeSHAs8CrwKGL970onAvcue7x8du295oyQ7GfZE2L59+6Ti1QxYbaqwU4il9Wm9pzHaGff9wCeBvwD+Bnh8g+faVVWDqhosLCxsXZCaOatNFXYKsbQ+nRTCq+qKqnpRVb0MeAj4yliTA8BJy54/Z3RM2pDVpgo7hVhan06m3CZ5ZlU9kGQ7w3rGWWNNdgOXJPkw8GLg4aq6b/w88n7YTa02VdgpxNL6dLVO409HNY3HgLdX1XeSvBWgqi4HrmNY69gLfA94c0dxTrWux+P7lrBWu3e49xSXmuskaVTVP1jh2OXLHhfw9laD6qHl4/FHHr6NPXc/2NqXX9cJS1I33Eakx7ocj7eALM0ntxHpsS7H4y0gS/PJpNFzXY3HW0CW5pNJo4empQBtAVmaPyaNnrEALalLFsJ7xgJ0M+4nJU2GPY2eOVQBelqGrrpkb0yaHJNGz6xVgPbLcqjL9SvSrDNp9NBqBWi/LIecDixNjkljhvhlOeR0YGlyTBozxC/LH3I6sDQZJo0ZMF78bvpladFc0nqZNHpuo8Vvi+aSNsJ1Gj230XUbs7Dew7UYUvvsaUxAm8M+Gy1+971obk9J6oZJY4u1/WW20eJ334vmTi+WumHS2GJdfJkdqvi9Ws9nq2YYdVFQ73tPSeork8YWm7Yvs0n3fLoaJup7T0nqK5PGFpu2L7NJ93y6HCZyLYbUPpPGBEzTl9mkez7T1rOSNFmpqvb/0eTdwC8DBXwReHNVfX/Z628CfhM4MDr0u1X1wbXOORgManFxcTIB99ykaw4uEpT6K8mtVTVo2r71nkaSE4F3Ai+oqkeTfAS4ELhqrOk1VXVJ2/HNokn3fKapZyVpsrpa3HcYcGSSw4CnAd/oKA5J0jq0njSq6gDwW8A9wH3Aw1X1yRWa/lKSLyS5NslJK50ryc4ki0kWl5aWJhi1JAk6SBpJjgYuAE4Bng08Pckbxpr9L2BHVf094AbgQyudq6p2VdWgqgYLCwuTDFuSRDfDUy8H7qqqpap6DPgo8NLlDarq21X1g9HTDwIvajlGSdIKukga9wBnJXlakgDnAF9a3iDJCcuenj/+uiSpG63PnqqqW5JcC9wGHAQ+B+xKchmwWFW7gXcmOX/0+oPAm9qOU5L04zpZpzEJrtOQpPVb7zoN76chSWrMpCFJasykIUlqzKTRU97qVFIX3OW2h7zVqaSu2NPooeX3sKgaPpekNpg0esh7WEjqisNTPTRtdweUND9MGj3lPSwkdcHhKUlSYyYNSVJjJg1JUmMmDUlSYyYNXF0tSU3N/ewpV1dLUnNz39NwdbUkNTf3ScPV1ZLU3NwPT7m6WpKam/ukAa6ulqSmOhmeSvLuJHckuT3J1UmOGHv9qUmuSbI3yS1JdnQRpyTpR7WeNJKcCLwTGFTV6cA24MKxZhcDD1XVzwD/FXh/u1EemtN0Jc2jroanDgOOTPIY8DTgG2OvXwC8d/T4WuB3k6Sqqr0QV+c0XUnzqvWeRlUdAH4LuAe4D3i4qj451uxE4N5R+4PAw8Cx4+dKsjPJYpLFpaWlyQa+jNN0Jc2rLoanjmbYkzgFeDbw9CRv2Mi5qmpXVQ2qarCwsLCVYa7JabqS5lUXw1MvB+6qqiWAJB8FXgr80bI2B4CTgP1JDgN+Cvh224Guxmm6kuZVF0njHuCsJE8DHgXOARbH2uwGLgI+C7wG+NS01DOe5DRdSfOoi5rGLQyL27cBXxzFsCvJZUnOHzW7Ajg2yV7gV4BL245TkvTjMmW/wG/YYDCoxcXxDoskaS1Jbq2qQdP2c7/3lCSpOZOGJKkxk4YkqTGThiSpMZPGFnEvKknzwK3Rt4B7UUmaF/Y0tsBm96KylyKpL+xpbIHN7EVlL0VSn5g0tsBm9qJa3ks58vBt7Ln7QZOGpKll0tgiG92Lyh1zJfWJSaNj7pgrqU9MGlPAHXMl9YWzpyRJjZk0JEmNmTQkSY2ZNCRJjZk0NsAV3JLmlbOn1skV3JLmmT2NddrsPlOS1GcmjXVyBbekedb68FSS5wHXLDt0KvAfquq3l7U5G/g4cNfo0Eer6rKWQlyTK7glzbPWk0ZVfRn4OYAk24ADwP9coelfVdV5LYbWmCu4Jc2rroenzgG+VlVf7zgOSVIDXSeNC4GrV3ntJUk+n+TPk/ydlRok2ZlkMcni0tLS5KKUJAEdJo0kPwGcD/zJCi/fBpxcVT8LfAD42ErnqKpdVTWoqsHCwsLEYpUkDXXZ03glcFtVfXP8har6blU9Mnp8HXB4kuPaDlCS9KO6TBqvZ5WhqSTPSpLR4zMZxvntFmOTJK2gkxXhSZ4O/CLwL5cdeytAVV0OvAZ4W5KDwKPAhVVVXcQqSfqhzMp3cZIlYD2zsI4DvjWhcPrA6/f6vf75tfz6T66qxkXhmUka65VksaoGXcfRFa/f6/f6vf6N/GzXU24lST1i0pAkNTbPSWNX1wF0zOufb17/fNvw9c9tTUOStH7z3NOQJK2TSUOS1NhMJ40k5yb5cpK9SS5d4fWnJrlm9PotSXZ0EObENLj+X0lyZ5IvJLkxycldxDlJh3oPlrX7pSSVZKamYTa5/iSvHX0O7kjyx23HOEkN/g9sT/LpJJ8b/T94VRdxTkqSK5M8kOT2VV5Pkt8ZvT9fSPLCQ560qmbyD7AN+BrDmzz9BPB54AVjbf4VcPno8YXANV3H3fL1/yPgaaPHb5ul62/6HozaPQO4CbgZGHQdd8ufgdOAzwFHj54/s+u4W77+XcDbRo9fANzdddxb/B68DHghcPsqr78K+HMgwFnALYc65yz3NM4E9lbVvqr6W+DDwAVjbS4APjR6fC1wzpN7Xs2AQ15/VX26qr43enoz8JyWY5y0Jp8BgF8H3g98v83gWtDk+t8C/F5VPQRQVQ+0HOMkNbn+An5y9PingG+0GN/EVdVNwINrNLkA+MMauhn46SQnrHXOWU4aJwL3Lnu+f3RsxTZVdRB4GDi2legmr8n1L3cxw984Zskh34NRd/ykqvqzNgNrSZPPwHOB5yb530luTnJua9FNXpPrfy/whiT7geuAd7QT2tRY7/dENxsWarokeQMwAP5h17G0KclTgP8CvKnjULp0GMMhqrMZ9jRvSvJ3q+o7XQbVotcDV1XVf07yEuC/Jzm9qp7oOrBpNcs9jQPAScueP2d0bMU2SQ5j2D2dlS3Ym1w/SV4O/Hvg/Kr6QUuxteVQ78EzgNOBzyS5m+GY7u4ZKoY3+QzsB3ZX1WNVdRfwFYZJZBY0uf6LgY8AVNVngSMYbuY3Lxp9Tyw3y0ljD3BaklNGdwm8ENg91mY3cNHo8WuAT9WoOjQDDnn9SX4e+G8ME8YsjWU/ac33oKoerqrjqmpHVe1gWNc5v6oWuwl3yzX5P/Axhr0MRjc6ey6wr8UYJ6nJ9d8DnAOQ5PkMk8Y83Tt6N/DG0Syqs4CHq+q+tX5gZoenqupgkkuA6xnOoriyqu5IchmwWFW7gSsYdkf3MiwWXdhdxFur4fX/JnAU8Cej+v89VXV+Z0FvsYbvwcxqeP3XA69IcifwOPCrVTUTve2G1/9vgD9I8m6GRfE3zdAvjiS5muEvBceN6jbvAQ6H/3/vousYzqDaC3wPePMhzzlD748kacJmeXhKkrTFTBqSpMZMGpKkxkwakqTGTBqSpMZMGpKkxkwakqTGTBrShCQ5Y3SPgiOSPH10v4rTu45L2gwX90kTlOQ/Mtya4khgf1X9p45DkjbFpCFN0GjPoz0M79Xx0qp6vOOQpE1xeEqarGMZ7u/1DIY9DqnX7GlIE5RkN8M7xp0CnFBVl3QckrQpM7vLrdS1JG8EHquqP06yDfg/Sf5xVX2q69ikjbKnIUlqzJqGJKkxk4YkqTGThiSpMZOGJKkxk4YkqTGThiSpMZOGJKmx/wfAG63FOITbYAAAAABJRU5ErkJggg==\n",
=======
      "image/png": "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\n",
>>>>>>> upstream/main
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.scatter(x,y, s=8); plt.xlabel(\"x\"); plt.ylabel(\"y\"); "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You want to find **parameters** (weights) $a$ and $b$ such that you minimize the *error* between the points and the line $a\\cdot x + b$. Note that here $a$ and $b$ are unknown. For a regression problem the most common *error function* or *loss function* is the **mean squared error** ($\\sum_i (\\hat{y}_i - y_i)^2$). "
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 3,
=======
   "execution_count": 25,
>>>>>>> upstream/main
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse(y_hat, y): return ((y_hat - y) ** 2).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose we believe $a = 10$ and $b = 5$ then we can compute `y_hat` which is our *prediction* and then compute our error."
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 6,
=======
   "execution_count": 26,
>>>>>>> upstream/main
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
<<<<<<< HEAD
       "4.348681041707156"
      ]
     },
     "execution_count": 6,
=======
       "4.415032714457949"
      ]
     },
     "execution_count": 26,
>>>>>>> upstream/main
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat = lin(10,5,x)\n",
    "mse(y_hat, y)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 4,
=======
   "execution_count": 27,
>>>>>>> upstream/main
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse_loss(a, b, x, y): return mse(lin(a,b,x), y)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 8,
=======
   "execution_count": 28,
>>>>>>> upstream/main
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
<<<<<<< HEAD
       "4.348681041707156"
      ]
     },
     "execution_count": 8,
=======
       "4.415032714457949"
      ]
     },
     "execution_count": 28,
>>>>>>> upstream/main
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse_loss(10, 5, x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far we have specified the *model* (linear regression) and the *evaluation criteria* (or *loss function*). Now we need to handle *optimization*; that is, how do we find the best values for $a$ and $b$? How do we find the best *fitting* linear regression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Descent with Pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a fixed dataset $x$ and $y$ `mse_loss(a,b)` is a function of $a$ and $b$. We would like to find the values of $a$ and $b$ that minimize that function.\n",
    "\n",
    "**Gradient descent** is an algorithm that minimizes functions. Given a function defined by a set of parameters, gradient descent starts with an initial set of parameter values and iteratively moves toward a set of parameter values that minimize the function. This iterative minimization is achieved by taking steps in the negative direction of the function gradient.\n",
    "\n",
    "Here is gradient descent implemented in [PyTorch](http://pytorch.org/)."
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 9,
=======
   "execution_count": 29,
>>>>>>> upstream/main
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10000,), (10000,))"
      ]
     },
<<<<<<< HEAD
     "execution_count": 9,
=======
     "execution_count": 29,
>>>>>>> upstream/main
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# generate some more data\n",
    "x, y = gen_fake_data(10000, 3., 8.)\n",
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 10,
=======
   "execution_count": 30,
>>>>>>> upstream/main
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wrap x and y as tensor \n",
    "x = torch.tensor(x)\n",
    "y = torch.tensor(y)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 11,
=======
   "execution_count": 31,
>>>>>>> upstream/main
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
<<<<<<< HEAD
       "(tensor([-0.1036], dtype=torch.float64, requires_grad=True),\n",
       " tensor([0.1417], dtype=torch.float64, requires_grad=True))"
      ]
     },
     "execution_count": 11,
=======
       "(tensor([-1.2913], dtype=torch.float64, requires_grad=True),\n",
       " tensor([-2.0688], dtype=torch.float64, requires_grad=True))"
      ]
     },
     "execution_count": 31,
>>>>>>> upstream/main
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create random Tensors for weights, and wrap them in tensors.\n",
    "# Setting requires_grad=True indicates that we want to compute gradients with\n",
    "# respect to these tensors during the backward pass.\n",
    "a, b = np.random.randn(1), np.random.randn(1)\n",
    "a = torch.tensor(a, requires_grad=True)\n",
    "b = torch.tensor(b, requires_grad=True)\n",
    "a,b"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 12,
=======
   "execution_count": 32,
>>>>>>> upstream/main
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "89.13339382483422\n",
      "0.7006591566766074\n",
      "0.1267407737945364\n",
      "0.11544386507218363\n",
      "0.10950120940242104\n",
      "0.10495036804221365\n",
      "0.10145208920735659\n",
      "0.0987628410655608\n",
      "0.09669552230504504\n",
      "0.09510630232922512\n"
=======
      "150.75314613539416\n",
      "1.0787729848098095\n",
      "0.13310958838824927\n",
      "0.1184308950677309\n",
      "0.11164307690140554\n",
      "0.10649173388918218\n",
      "0.10256160453019604\n",
      "0.0995630492815676\n",
      "0.09727525263480687\n",
      "0.09552974085392134\n"
>>>>>>> upstream/main
     ]
    }
   ],
   "source": [
    "learning_rate = 1e-3\n",
    "for t in range(10000):\n",
    "    # Forward pass: compute predicted y using operations on Variables\n",
    "    loss = mse_loss(a,b,x,y)\n",
    "    if t % 1000 == 0: print(loss.item())\n",
    "    \n",
    "    # Computes the gradient of loss with respect to all Variables with requires_grad=True.\n",
    "    # After this call a.grad and b.grad will be Variables holding the gradient\n",
    "    # of the loss with respect to a and b respectively\n",
    "    loss.backward()\n",
    "    \n",
    "    # Update a and b using gradient descent; a.data and b.data are Tensors,\n",
    "    # a.grad and b.grad are Variables and a.grad.data and b.grad.data are Tensors\n",
    "    a.data -= learning_rate * a.grad.data\n",
    "    b.data -= learning_rate * b.grad.data\n",
    "    \n",
    "    # Zero the gradients\n",
    "    a.grad.data.zero_()\n",
    "    b.grad.data.zero_()    "
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 13,
=======
   "execution_count": 33,
>>>>>>> upstream/main
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "tensor([3.2284], dtype=torch.float64, requires_grad=True) tensor([7.8787], dtype=torch.float64, requires_grad=True)\n"
=======
      "tensor([3.2191], dtype=torch.float64, requires_grad=True) tensor([7.8805], dtype=torch.float64, requires_grad=True)\n"
>>>>>>> upstream/main
     ]
    }
   ],
   "source": [
    "# not that a and b should be close to 3 and 8 respectively\n",
    "print(a,b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simplified GD Loop"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 14,
=======
   "execution_count": 34,
>>>>>>> upstream/main
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=1, out_features=1, bias=True)"
      ]
     },
<<<<<<< HEAD
     "execution_count": 14,
=======
     "execution_count": 34,
>>>>>>> upstream/main
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# linear tranformation with input dimension=1 and output dimension=1\n",
    "nn.Linear(1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models in Pytorch"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 15,
=======
   "execution_count": 35,
>>>>>>> upstream/main
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=1, out_features=1, bias=True)\n",
       ")"
      ]
     },
<<<<<<< HEAD
     "execution_count": 15,
=======
     "execution_count": 35,
>>>>>>> upstream/main
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# simple way of specifying a linear regression model\n",
    "model = torch.nn.Sequential(\n",
    "    nn.Linear(1, 1),\n",
    ")\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 16,
=======
   "execution_count": 36,
>>>>>>> upstream/main
   "metadata": {},
   "outputs": [],
   "source": [
    "# equivalent way of specifiying the same model\n",
    "class LinearRegression(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LinearRegression, self).__init__()\n",
    "        self.lin = nn.Linear(1, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.lin(x)\n",
    "        return x \n",
    "model =  LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 17,
=======
   "execution_count": 37,
>>>>>>> upstream/main
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Parameter containing:\n",
<<<<<<< HEAD
      "tensor([[0.6002]], requires_grad=True), Parameter containing:\n",
      "tensor([-0.1561], requires_grad=True)]\n"
=======
      "tensor([[0.7918]], requires_grad=True), Parameter containing:\n",
      "tensor([-0.8356], requires_grad=True)]\n"
>>>>>>> upstream/main
     ]
    }
   ],
   "source": [
    "# note here we have just two parameters, why? (a,b)\n",
    "print([p for p in model.parameters()])"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 18,
=======
   "execution_count": 38,
>>>>>>> upstream/main
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10000])"
      ]
     },
<<<<<<< HEAD
     "execution_count": 18,
=======
     "execution_count": 38,
>>>>>>> upstream/main
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, y = gen_fake_data(10000, 3., 8.)\n",
    "x = torch.tensor(x).float()\n",
    "y = torch.tensor(y).float()\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 19,
=======
   "execution_count": 39,
>>>>>>> upstream/main
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10000, 1])"
      ]
     },
<<<<<<< HEAD
     "execution_count": 19,
=======
     "execution_count": 39,
>>>>>>> upstream/main
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# you have to be careful with the dimensions that your model is expecting\n",
    "# unsqueeze dim=1 transforms [10000] to [10000, 1]\n",
    "x = torch.unsqueeze(x, 1) #use x.view(-1,1)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 20,
=======
   "execution_count": 40,
>>>>>>> upstream/main
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "tensor([[0.1450],\n",
      "        [0.4223],\n",
      "        [0.2966],\n",
      "        ...,\n",
      "        [0.3074],\n",
      "        [0.1097],\n",
      "        [0.4020]], grad_fn=<AddmmBackward0>)\n"
=======
      "tensor([[-0.1413],\n",
      "        [-0.7320],\n",
      "        [-0.2927],\n",
      "        ...,\n",
      "        [-0.6377],\n",
      "        [-0.0953],\n",
      "        [-0.1042]], grad_fn=<AddmmBackward>)\n"
>>>>>>> upstream/main
     ]
    }
   ],
   "source": [
    "y_hat = model(x)\n",
    "print(y_hat)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 21,
=======
   "execution_count": 41,
>>>>>>> upstream/main
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10000, 1])"
      ]
     },
<<<<<<< HEAD
     "execution_count": 21,
=======
     "execution_count": 41,
>>>>>>> upstream/main
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat.shape"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10000])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
=======
   "execution_count": 42,
>>>>>>> upstream/main
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
<<<<<<< HEAD
       "tensor(88.1835, grad_fn=<MseLossBackward0>)"
      ]
     },
     "execution_count": 23,
=======
       "tensor(99.1306, grad_fn=<MseLossBackward>)"
      ]
     },
     "execution_count": 42,
>>>>>>> upstream/main
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = y.unsqueeze(1)\n",
    "F.mse_loss(y_hat, y)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 24,
=======
   "execution_count": 43,
>>>>>>> upstream/main
   "metadata": {},
   "outputs": [],
   "source": [
    "# validation data\n",
    "x_val, y_val = gen_fake_data(1000, 3., 8.)\n",
    "x_val = torch.tensor(x_val).float().unsqueeze(1)\n",
    "y_val = torch.tensor(y_val).float().unsqueeze(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizer\n",
    "Use the optim package to define an Optimizer that will update the weights of the model for us. Here we will use Adam"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 25,
=======
   "execution_count": 44,
>>>>>>> upstream/main
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.1\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 26,
=======
   "execution_count": 45,
>>>>>>> upstream/main
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "train loss 88.183 valid loss 84.965\n",
      "train loss 0.108 valid loss 0.115\n",
      "train loss 0.095 valid loss 0.101\n",
      "train loss 0.092 valid loss 0.098\n",
      "train loss 0.091 valid loss 0.097\n",
      "train loss 0.091 valid loss 0.096\n",
      "train loss 0.091 valid loss 0.096\n",
      "train loss 0.091 valid loss 0.096\n",
      "train loss 0.091 valid loss 0.096\n",
      "train loss 0.091 valid loss 0.096\n"
=======
      "train loss 99.131 valid loss 96.470\n",
      "train loss 0.111 valid loss 0.111\n",
      "train loss 0.096 valid loss 0.097\n",
      "train loss 0.092 valid loss 0.094\n",
      "train loss 0.091 valid loss 0.094\n",
      "train loss 0.090 valid loss 0.093\n",
      "train loss 0.090 valid loss 0.093\n",
      "train loss 0.090 valid loss 0.093\n",
      "train loss 0.090 valid loss 0.093\n",
      "train loss 0.090 valid loss 0.093\n"
>>>>>>> upstream/main
     ]
    }
   ],
   "source": [
    "for t in range(10000):\n",
    "    # Forward pass: compute predicted y using operations on Variables\n",
    "    model.train() # some layers have different behavior during train/and evaluation\n",
    "    y_hat = model(x)\n",
    "    loss = F.mse_loss(y_hat, y)\n",
    "       \n",
    "    # Before the backward pass, use the optimizer object to zero all of the\n",
    "    # gradients for the variables\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward() # computes gradients\n",
    "    \n",
    "    # Calling the step function on an Optimizer makes an update to its\n",
    "    # parameters\n",
    "    optimizer.step()\n",
    "    \n",
    "    # checking validation loss\n",
    "    model.eval()  # some layers have different behavior during train/and evaluation\n",
    "    y_hat_val = model(x_val)\n",
    "    val_loss = F.mse_loss(y_hat_val, y_val)\n",
    "    \n",
    "    if t % 1000 == 0: print(\"train loss %.3f valid loss %.3f\" % (loss.item(), val_loss.item()))"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 27,
=======
   "execution_count": 46,
>>>>>>> upstream/main
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Parameter containing:\n",
<<<<<<< HEAD
      "tensor([[3.0006]], requires_grad=True), Parameter containing:\n",
      "tensor([7.9955], requires_grad=True)]\n"
=======
      "tensor([[2.9967]], requires_grad=True), Parameter containing:\n",
      "tensor([7.9982], requires_grad=True)]\n"
>>>>>>> upstream/main
     ]
    }
   ],
   "source": [
    "print([p for p in model.parameters()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 5,
=======
   "execution_count": 53,
>>>>>>> upstream/main
   "metadata": {},
   "outputs": [],
   "source": [
    "# generating fake data\n",
    "# Here we generate some fake data\n",
    "def lin(a,b,x): return a*x+b\n",
    "\n",
    "def gen_logistic_fake_data(n, a, b):\n",
    "    x = np.random.uniform(-20,20, (n, 2))\n",
    "    x2_hat = lin(a,b, x[:,0])\n",
    "    y = x[:,1] > x2_hat\n",
    "    return x, y.astype(int)\n",
    "\n",
    "x, y = gen_logistic_fake_data(100, 1., 0.5)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 6,
=======
   "execution_count": 54,
>>>>>>> upstream/main
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
<<<<<<< HEAD
       "array([1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0,\n",
       "       0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0,\n",
       "       0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0,\n",
       "       1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1,\n",
       "       1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0])"
      ]
     },
     "execution_count": 6,
=======
       "array([1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1,\n",
       "       0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1,\n",
       "       0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1,\n",
       "       0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1,\n",
       "       0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 54,
>>>>>>> upstream/main
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 7,
=======
   "execution_count": 55,
>>>>>>> upstream/main
   "metadata": {},
   "outputs": [
    {
     "data": {
<<<<<<< HEAD
      "image/png": "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\n",
=======
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7ff65082fa00>]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
>>>>>>> upstream/main
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "t = np.arange(-20, 20, 0.2)\n",
    "import matplotlib.pyplot as plt\n",
    "plt.scatter(x[:,0],x[:,1],c=y, s=8)\n",
    "plt.xlabel(\"x1\"); plt.ylabel(\"x2\");\n",
    "plt.plot(t, t + 0.5, '--', c='gray');"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 8,
=======
   "execution_count": 56,
>>>>>>> upstream/main
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor(x)\n",
    "y = torch.tensor(y)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 9,
=======
   "execution_count": 57,
>>>>>>> upstream/main
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=2, out_features=1, bias=True)\n",
       ")"
      ]
     },
<<<<<<< HEAD
     "execution_count": 9,
=======
     "execution_count": 57,
>>>>>>> upstream/main
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = torch.nn.Sequential(\n",
    "    torch.nn.Linear(2, 1),\n",
    ")\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 10,
=======
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = model(x.float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
>>>>>>> upstream/main
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(7.4256, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)"
      ]
     },
<<<<<<< HEAD
     "execution_count": 10,
=======
     "execution_count": 69,
>>>>>>> upstream/main
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.binary_cross_entropy_with_logits(y_hat, y.unsqueeze(1).float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generating train and val data\n",
    "x, y = gen_logistic_fake_data(10000, 1., 0.5)\n",
    "x = torch.tensor(x).float()\n",
    "y = torch.tensor(y).float().unsqueeze(1)\n",
    "\n",
    "x_val, y_val = gen_logistic_fake_data(1000, 1., 0.5)\n",
    "x_val = torch.tensor(x_val).float()\n",
    "y_val = torch.tensor(y_val).float().unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.1\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss 7.151 valid loss 5.764\n",
      "train loss 0.024 valid loss 0.027\n",
      "train loss 0.019 valid loss 0.021\n",
      "train loss 0.016 valid loss 0.018\n",
      "train loss 0.013 valid loss 0.015\n",
      "train loss 0.011 valid loss 0.012\n",
      "train loss 0.009 valid loss 0.011\n",
      "train loss 0.008 valid loss 0.009\n",
      "train loss 0.007 valid loss 0.007\n",
      "train loss 0.006 valid loss 0.006\n"
     ]
    }
   ],
   "source": [
    "for t in range(10000):\n",
    "    # Forward pass: compute predicted y using operations on Variables\n",
    "    model.train()\n",
    "    y_hat = model(x)\n",
    "    loss = F.binary_cross_entropy_with_logits(y_hat, y)\n",
    "       \n",
    "    # Before the backward pass, use the optimizer object to zero all of the\n",
    "    # gradients for the variables\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    \n",
    "    # Calling the step function on an Optimizer makes an update to its\n",
    "    # parameters\n",
    "    optimizer.step()\n",
    "    \n",
    "    model.eval()\n",
    "    y_hat_val = model(x_val)\n",
    "    val_loss = F.binary_cross_entropy(torch.sigmoid(y_hat_val), y_val)\n",
    "    \n",
    "    if t % 1000 == 0: print(\"train loss %.3f valid loss %.3f\" % (loss.item(), val_loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Parameter containing:\n",
      "tensor([[-8.0842,  8.0862]], requires_grad=True), Parameter containing:\n",
      "tensor([-3.8579], requires_grad=True)]\n"
     ]
    }
   ],
   "source": [
    "print([p for p in model.parameters()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise: Instead of using `F.binary_cross_entropy(torch.sigmoid(y_hat), y)` try `F.binary_cross_entropy_with_logits(y_hat, y)`. Look at the documentation for `F.binary_cross_entropy_with_logits`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to take a vector back to numpy?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = gen_logistic_fake_data(10, 1., 0.5)\n",
    "x = torch.tensor(x).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  3.6044252 ,  13.593492  ],\n",
       "       [  7.5224466 , -14.180548  ],\n",
       "       [ -4.8933735 , -14.133529  ],\n",
       "       [  8.420092  ,  17.196589  ],\n",
       "       [ 16.815563  ,  -2.8977888 ],\n",
       "       [ -4.9162564 ,  -9.293126  ],\n",
       "       [ -0.07002173,   9.143694  ],\n",
       "       [  5.9479446 ,  18.582197  ],\n",
       "       [  5.559075  , -15.781488  ],\n",
       "       [ 13.089842  ,  -6.2278466 ]], dtype=float32)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise: Compute the accuracy of the validation logistic regression model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset and Data loaders \n",
    "\n",
    "Nearly all of deep learning is powered by one very important algorithm: **stochastic gradient descent (SGD)**. SGD can be seeing as an approximation of **gradient descent** (GD). In GD you have to run through *all* the samples in your training set to do a single itaration. In SGD you use *only one* or *a subset*  of training samples to do the update for a parameter in a particular iteration. The subset use in every iteration is called a **batch** or **minibatch**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = torch.nn.Sequential(\n",
    "    torch.nn.Linear(1, 1),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lin(a,b,x): return a*x+b\n",
    "\n",
    "def gen_fake_data(n, a, b):\n",
    "    x = np.random.uniform(0,1,n) \n",
    "    y = lin(a,b,x) + 0.1 * np.random.normal(0,3,n)\n",
    "    return x.astype(np.float32), y.astype(np.float32)\n",
    "\n",
    "# create a dataset\n",
    "class RegressionDataset(Dataset):\n",
    "    def __init__(self, a=3, b=8, n=10000):\n",
    "        x, y = gen_fake_data(n, a, b)\n",
    "        x = torch.from_numpy(x).unsqueeze(1)\n",
    "        y = torch.from_numpy(y)\n",
    "        self.x, self.y = x, y\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.x[idx], self.y[idx]\n",
    "    \n",
    "fake_train_ds = RegressionDataset()\n",
    "fake_valid_ds = RegressionDataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = fake_train_ds[10000-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0.6714]), tensor(9.4025))"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we are going to create a data loader. The data loader provides the following features:\n",
    "* Batching the data\n",
    "* Shuffling the data\n",
    "* Load the data in parallel using multiprocessing workers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = DataLoader(fake_train_ds, batch_size=1000, shuffle=True)\n",
    "valid_dl = DataLoader(fake_valid_ds, batch_size=1000, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting a batch of data\n",
    "x, y = next(iter(train_dl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1000, 1]), torch.Size([1000]))"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1000, 1])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2(x).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "\n",
    "def val_metric(model, valid_dl):\n",
    "    model.eval()\n",
    "    losses = []\n",
    "    y_hats = []\n",
    "    ys = []\n",
    "    for x, y in valid_dl:\n",
    "        y = y.unsqueeze(1)\n",
    "        y_hat = model(x.float())\n",
    "        loss = F.mse_loss(y_hat, y.float())\n",
    "        y_hats.append(y_hat.detach().numpy())\n",
    "        ys.append(y.numpy())\n",
    "        losses.append(loss.item())\n",
    "    \n",
    "    ys = np.concatenate(ys)\n",
    "    y_hats = np.concatenate(y_hats)\n",
    "    return np.mean(losses), r2_score(ys, y_hats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(88.36927719116211, -103.92606583642083)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_loss, valid_r2 = val_metric(model2, valid_dl)\n",
    "valid_loss, valid_r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "## train_loop function\n",
    "def train_loop(model, train_dl, valid_dl, optimizer, epochs):\n",
    "    losses = []\n",
    "    for i in range(epochs):\n",
    "        model.train()\n",
    "        for x, y in train_dl:\n",
    "            y = y.unsqueeze(1)\n",
    "            y_hat = model(x.float())\n",
    "            loss = F.mse_loss(y_hat, y.float())\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            losses.append(loss.item())\n",
    "        \n",
    "        train_loss = np.mean(losses)\n",
<<<<<<< HEAD
    "        valid_loss, valid_r2 = val_metric(model, valid_dl)\n",
    "        print(\"train loss %.3f valid loss %.3f auc roc %.3f\" % (train_loss, valid_loss, valid_r2))"
=======
    "        valid_loss, valid_auc = val_metric(model, valid_dl)\n",
    "        print(\"train loss %.3f valid loss %.3f R^2 %.3f\" % \n",
    "              (train_loss, valid_loss, valid_auc))"
>>>>>>> upstream/main
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = torch.nn.Sequential(\n",
    "    torch.nn.Linear(1, 1),\n",
    ")\n",
    "learning_rate = 1\n",
    "optimizer = torch.optim.Adam(model2.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss 28.877 valid loss 8.545 R^2 -9.145\n",
      "train loss 19.607 valid loss 2.420 R^2 -1.874\n",
      "train loss 13.777 valid loss 3.070 R^2 -2.645\n",
      "train loss 10.656 valid loss 0.649 R^2 0.229\n",
      "train loss 8.649 valid loss 0.158 R^2 0.812\n",
      "train loss 7.245 valid loss 0.169 R^2 0.800\n",
      "train loss 6.228 valid loss 0.136 R^2 0.838\n",
      "train loss 5.463 valid loss 0.103 R^2 0.878\n",
      "train loss 4.866 valid loss 0.093 R^2 0.890\n",
      "train loss 4.389 valid loss 0.089 R^2 0.894\n",
      "train loss 3.998 valid loss 0.089 R^2 0.895\n",
      "train loss 3.672 valid loss 0.089 R^2 0.895\n",
      "train loss 3.397 valid loss 0.089 R^2 0.895\n",
      "train loss 3.161 valid loss 0.089 R^2 0.895\n",
      "train loss 2.956 valid loss 0.089 R^2 0.895\n",
      "train loss 2.777 valid loss 0.089 R^2 0.895\n",
      "train loss 2.619 valid loss 0.089 R^2 0.895\n",
      "train loss 2.478 valid loss 0.089 R^2 0.895\n",
      "train loss 2.352 valid loss 0.089 R^2 0.895\n",
      "train loss 2.239 valid loss 0.089 R^2 0.895\n"
     ]
    }
   ],
   "source": [
    "train_loop(model2, train_dl, valid_dl, optimizer, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss 0.097 valid loss 0.096 R^2 0.886\n",
      "train loss 0.094 valid loss 0.090 R^2 0.893\n",
      "train loss 0.093 valid loss 0.089 R^2 0.895\n",
      "train loss 0.092 valid loss 0.089 R^2 0.895\n",
      "train loss 0.092 valid loss 0.089 R^2 0.894\n",
      "train loss 0.091 valid loss 0.089 R^2 0.895\n",
      "train loss 0.091 valid loss 0.089 R^2 0.895\n",
      "train loss 0.091 valid loss 0.089 R^2 0.895\n",
      "train loss 0.091 valid loss 0.089 R^2 0.895\n",
      "train loss 0.091 valid loss 0.089 R^2 0.895\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam(model2.parameters(), lr=0.1)\n",
    "train_loop(model2, train_dl, valid_dl, optimizer, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss 0.090 valid loss 0.089 R^2 0.894\n",
      "train loss 0.090 valid loss 0.089 R^2 0.895\n",
      "train loss 0.090 valid loss 0.089 R^2 0.895\n",
      "train loss 0.090 valid loss 0.089 R^2 0.895\n",
      "train loss 0.090 valid loss 0.089 R^2 0.895\n",
      "train loss 0.090 valid loss 0.089 R^2 0.895\n",
      "train loss 0.090 valid loss 0.089 R^2 0.895\n",
      "train loss 0.090 valid loss 0.089 R^2 0.895\n",
      "train loss 0.090 valid loss 0.089 R^2 0.895\n",
      "train loss 0.090 valid loss 0.089 R^2 0.895\n",
      "train loss 0.090 valid loss 0.089 R^2 0.895\n",
      "train loss 0.090 valid loss 0.089 R^2 0.895\n",
      "train loss 0.090 valid loss 0.089 R^2 0.895\n",
      "train loss 0.090 valid loss 0.089 R^2 0.895\n",
      "train loss 0.090 valid loss 0.089 R^2 0.895\n",
      "train loss 0.090 valid loss 0.089 R^2 0.895\n",
      "train loss 0.090 valid loss 0.089 R^2 0.895\n",
      "train loss 0.090 valid loss 0.089 R^2 0.895\n",
      "train loss 0.090 valid loss 0.089 R^2 0.895\n",
      "train loss 0.090 valid loss 0.089 R^2 0.895\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam(model2.parameters(), lr=0.01)\n",
    "train_loop(model2, train_dl, valid_dl, optimizer, epochs=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise**: Play with the training of the previous model to get the max R^2 possible. Can you use larger learning rates or more epochs? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References\n",
    "* https://pytorch.org/docs/stable/index.html\n",
    "* http://pytorch.org/tutorials/beginner/pytorch_with_examples.html\n",
    "* https://hsaghir.github.io/data_science/pytorch_starter/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "nav_menu": {},
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "116px",
    "width": "251px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
